---
title: "Generate Excel"
author: "Graeme Ford"
date: "07/10/2019"
output: 
  pdf_document: 
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("F:/GitHub/Pharmacogenetics Snakemake/")
library(tidyverse)
library(openxlsx)
```

# Variant Effect Prediction (VEP) analysis:

For my Honours project, I have identified a list of SNP's associated with my three genes of interest. TO take my research a step further I have performed Variant Effect Prediction (VEP) using the [e! Ensembl VEP online tool] (https://www.ensembl.org/Homo_sapiens/Tools/VEP/Results?tl=rmJOG8c3fvsDcyMu-5710067). What this does is look at the nature of the variant (i.e. the genetic change that took place to produce this variant/individual) and run several algorithms to predict what type of effect that change will have on the end gene product (e.g. protein) and intemediary products (e.g. mRNA). This is done by running several algorithms which compare the change documented to various databases (In my case, Ensembl/GENCODE and RefSeq), and makes a prediction based on the reference transcript. As such, the tool returns multiple possible predictions based on which transcript was used (remember biologically, one gene can produce several mRNA variants and by extension, several protein isoforms). One challendge will be to filter that down to the canonical (currently accepted as canon) transcripts by using a list of canonical transcript ID's obtained from UCSC.

# Step One: Get everything ready to go!

I have run my samples through VEP and downloaded the results as three `.txt` files (one per gene, containing all my samples in each). Now I need to go through the results and filter them down to predictions made off of the canonical transcript sequence where possible (and where not, select the longest available transcript).
```{r Import Data}
# My Variant-Effect-Prediction results from e! Ensembl:
CYP2A6_VEP <- read.table("../Final/CYP2A6_VEP.txt", sep = "\t", header = TRUE, comment.char = "", quote = "")
CYP2B6_VEP <- read.table("../Final/CYP2B6_VEP.txt", sep = "\t", header = TRUE, comment.char = "", quote = "")
UGT2B7_VEP <- read.table("../Final/UGT2B7_VEP.txt", sep = "\t", header = TRUE, comment.char = "", quote = "")

# Frequency analysis reports from PLINK-1.9:
ALL_1_SUPER_Frqx <- read.table("..Final/SUPER/ALL_CYP2A6_SUPER.frq.strat", 
                               sep = "",
                               header = TRUE) %>% 
  select(SNP, A1, A2, CLST, MAF) %>%
  spread(CLST, MAF)
ALL_2_SUPER_Frqx <- read.table("..Final/SUPER/ALL_CYP2B6_SUPER.frq.strat", 
                               sep = "", 
                               header = TRUE) %>% 
  select(SNP, A1, A2, CLST, MAF) %>%
  spread(CLST, MAF)
ALL_3_SUPER_Frqx <- read.table("..Final/SUPER/ALL_UGT2B7_SUPER.frq.strat", 
                               sep = "", 
                               header = TRUE) %>% 
  select(SNP, A1, A2, CLST, MAF) %>%
  spread(CLST, MAF)

# Fishers-Exact scores as calculated in the Frequency Analysis document:
Fishers_1 <- read.table("../Fishers/Fishers_1.csv", sep="\t", header = TRUE)
Fishers_2 <- read.table("../Fishers/Fishers_2.csv", sep="\t", header = TRUE)
Fishers_3 <- read.table("../Fishers/Fishers_3.csv", sep="\t", header = TRUE)

# A list of canonical transcript IDs obtained from UCSC:
canonicalTranscripts <- read.table("../rawData/canonical.txt", header = TRUE, comment.char = "")
```

# Step two: Filter down to canonical ID's

Next up, I will be using the seperate function from the `tidyr` package and SQL-type join functions from the `dplyr` package (both in the `tidyverse` bulk package) to clean up and trim my results down. First off, the seperate function can take one column and, using a REGEX (Regular Expression), split it into two columns. This is necicary as my transcript ID's from VEP are in the form of transcript ID and version (E.g. ENST00000301141.10) wheras we need just the build number to compare to our UCSC list.

Folowing this, I used the `semi_join()` function to actually perform the merge. This part is pretty self explanitory. It looks for matching entries and lines them up together in a new, single, dataframe.

```{r Generate dataframes}
VEP_1_FILTERED <- CYP2A6_VEP %>% 
  separate(col = Feature, into = c("Feature", "FeatureVersion"), sep = "\\.") %>% 
  semi_join(canonicalTranscripts, by = c("Feature" = "hg19.refGene.name")) %>%
  select(
    X.Uploaded_variation,
    Location,
    Allele,
    Existing_variation,
    Consequence,
    Feature,
    SOURCE,
    SIFT,
    PolyPhen,
    Condel,
    CADD_PHRED,
    PHENOTYPES
  )
VEP_2_FILTERED <- CYP2B6_VEP %>% 
  separate(col = Feature, into = c("Feature", "FeatureVersion"), sep = "\\.") %>% 
  semi_join(canonicalTranscripts, by = c("Feature" = "hg19.refGene.name")) %>%
  select(
    X.Uploaded_variation,
    Location,
    Allele,
    Existing_variation,
    Consequence,
    Feature,
    SOURCE,
    SIFT,
    PolyPhen,
    Condel,
    CADD_PHRED,
    PHENOTYPES
  )
VEP_3_FILTERED <- UGT2B7_VEP %>%
  separate(col = Feature, into = c("Feature", "FeatureVersion"), sep = "\\.") %>%
  # semi_join(canonicalTranscripts, by = c("Feature" = "hg19.refGene.name")) %>%
  filter(Feature == "NM_001349568") %>%
  select(
    X.Uploaded_variation,
    Location,
    Allele,
    Existing_variation,
    Consequence,
    Feature,
    SOURCE,
    SIFT,
    PolyPhen,
    Condel,
    CADD_PHRED,
    PHENOTYPES
  )

# Just to double check, lets try an `anti_join()` and see of we have any variants listed which dont match up:
anti_join(VEP_1_FILTERED, Fishers_1, by = c("X.Uploaded_variation" = "SNP"))
anti_join(VEP_2_FILTERED, Fishers_2, by = c("X.Uploaded_variation" = "SNP"))
anti_join(VEP_3_FILTERED, Fishers_3, by = c("X.Uploaded_variation" = "SNP"))

# No mismatches. Great! Now we can go ahead and combine our Fishers-Exact scores with our Variant Effect Predictions:
VEP_FINAL_1 <- full_join(VEP_1_FILTERED, ALL_1_SUPER_Frqx, by = c("X.Uploaded_variation"="SNP")) %>% full_join(Fishers_1, by = c("X.Uploaded_variation" = "SNP"))
VEP_FINAL_2 <- full_join(VEP_2_FILTERED, ALL_2_SUPER_Frqx, by = c("X.Uploaded_variation"="SNP")) %>% full_join(Fishers_2, by = c("X.Uploaded_variation" = "SNP"))
VEP_FINAL_3 <- full_join(VEP_3_FILTERED, ALL_3_SUPER_Frqx, by = c("X.Uploaded_variation"="SNP")) %>% full_join(Fishers_3, by = c("X.Uploaded_variation" = "SNP"))
summary(ALL_1_SUPER_Frqx)

# Dependant on Frequency Analysis (UpSetR).rmd datasets and env variables:
VEP_FINAL_1 <- full_join(VEP_FINAL_1, ALL_1_Alleles %>% select(SNP, Unique), c("X.Uploaded_variation"="SNP"))

filter(VEP_FINAL_1, as.character(Allele) != as.character(A1))

filter(VEP_FINAL_1, str_detect(Condel, "deleterious"))
```

```{r Export to Excel, include=FALSE}

file <- createWorkbook()

addWorksheet(file, "CYP2A6")
freezePane(file, "CYP2A6", firstRow = TRUE)
writeData(file, x = VEP_FINAL_1, sheet = "CYP2A6", colNames=TRUE, rowNames=FALSE, keepNA = TRUE)

addWorksheet(file, "CYP2B6")
freezePane(file, "CYP2B6", firstRow = TRUE)
writeData(file, x = VEP_FINAL_2, sheet = "CYP2B6" , colNames=TRUE, rowNames=FALSE, keepNA = TRUE)

addWorksheet(file, "UGT2B7")
freezePane(file, "UGT2B7", firstRow = TRUE)
writeData(file, x = VEP_FINAL_3, sheet = "UGT2B7" , colNames=TRUE, rowNames=FALSE, keepNA = TRUE)

setColWidths(file, sheet = "CYP2A6", cols = 1:16, widths = "auto")
setColWidths(file, sheet = "CYP2B6", cols = 1:16, widths = "auto")
setColWidths(file, sheet = "UGT2B7", cols = 1:16, widths = "auto")
saveWorkbook(file, file = "../data/Supplementary Table.xlsx", overwrite = TRUE)
```

# Step Three: Make some basic summary figures

Ok so we have a workable dataframe of all my VEP predictions. Now lets make some basic summary figures and such for a publications results section (A.k.a. the fluff).

```{r Make some Fluff}
# First lets see how many of each consequence we have:
VEP_1_PIE <- VEP_FINAL_1 %>% count(Consequence) %>% filter(!is.na(Consequence)) %>% mutate(gene = "CYP2A6")
VEP_2_PIE <- VEP_FINAL_2 %>% count(Consequence) %>% filter(!is.na(Consequence)) %>% mutate(gene = "CYP2B6")
VEP_3_PIE <- VEP_FINAL_3 %>% count(Consequence) %>% filter(!is.na(Consequence)) %>% mutate(gene = "UGT2B7")
VEP_ALL_SUMMARY <- full_join(VEP_1_PIE, VEP_2_PIE, by = "Consequence") %>% full_join(VEP_3_PIE, by = "Consequence") %>% mutate(total = n + n.x + n.y) %>% mutate_all(funs(ifelse(is.na(.), 0, .))) %>% mutate(n = total, gene = "ALL") %>% select(Consequence, n, gene)

VEP_ALL_PIE <- rbind(VEP_1_PIE, VEP_2_PIE, VEP_3_PIE, VEP_ALL_SUMMARY)

VEP_PIE <- function(df, title) {
  title<-eval(parse(text = "title"))
  df <- df %>%
  arrange(desc(Consequence)) %>%
  mutate(lab.ypos = cumsum(n) - 0.5*n)
  
  ggplot(data = df, mapping = aes(x = "", y = df$n, fill = df$Consequence))+
    scale_fill_viridis_d()+
    geom_bar(width = 1, stat = "identity")+
    theme(
      axis.ticks.x = element_blank(),
      axis.title.x = element_blank(),
      axis.text.y = element_text(color = "black", size = 15),
      panel.grid = element_blank(),
      axis.text.x=element_blank(),
      title = element_text(face = "bold", size = 20),
      legend.title = element_text(face = "bold"),
      legend.text = element_text(size = 13),
      strip.text = element_text(face = "bold", size = 15)
    )+
    labs(
      title = title,
      fill = "Predicted consequence",
      y = "Count"
    )+
    facet_wrap(.~df$gene, scales = "free_y", nrow = 1)
}

VEP_PIE_PLOT <- VEP_PIE(VEP_ALL_PIE, "Predicted Consequence")
VEP_PIE_PLOT

```

```{r Save Graph}
ggsave("Graphs/Predicted Consequences.png", plot = VEP_PIE_PLOT, units="mm", width = 500, height = 200, dpi = 300)
```

# Filter

Now that we have collated dataframes (and exported them to excel as supplementary tables [I did that in the background like a ninja!]) for supplementary table purposes, lets also try and filter out some subsets of interest, for example variants with deleterous SIFT and PolyPhen scores, etc.

```{r Filter by Deleteriousness}
VEP_Deleterious_1 <- VEP_FINAL_1 %>% filter(str_detect(PolyPhen, "damaging") | str_detect(SIFT, "deleterious") | str_detect(Condel, "deleterious"))
inner_join(VEP_Deleterious_1, ALL_1_SUPER_Frqx_Alel, by = c("X.Uploaded_variation" = "SNP"))
VEP_Deleterious_2 <- VEP_FINAL_2 %>% filter(str_detect(PolyPhen, "damaging") | str_detect(SIFT, "deleterious") | str_detect(Condel, "deleterious"))
inner_join(VEP_Deleterious_2, ALL_2_SUPER_Frqx_Alel, by = c("X.Uploaded_variation" = "SNP"))
VEP_Deleterious_3 <- VEP_FINAL_3 %>% filter(str_detect(PolyPhen, "damaging") | str_detect(SIFT, "deleterious") | str_detect(Condel, "deleterious"))
inner_join(VEP_Deleterious_3, ALL_3_SUPER_Frqx_Alel, by = c("X.Uploaded_variation" = "SNP"))

VEP_Deleterious_1 <- VEP_FINAL_2 %>% filter(
  ((str_detect(PolyPhen, "probably_damaging")|str_detect(PolyPhen, "possibly_damaging")) & str_detect(SIFT, "tolerated") & str_detect(Condel, "deleterious")))
inner_join(VEP_Deleterious_1, ALL_1_SUPER_Frqx_Clin, by = c("X.Uploaded_variation" = "SNP"))
VEP_Deleterious_2 <- VEP_FINAL_2 %>% filter(str_detect(PolyPhen, "damaging") | str_detect(SIFT, "deleterious") | str_detect(Condel, "deleterious"))
inner_join(VEP_Deleterious_2, ALL_2_SUPER_Frqx_Clin, by = c("X.Uploaded_variation" = "SNP"))
VEP_Deleterious_3 <- VEP_FINAL_3 %>% filter(str_detect(PolyPhen, "damaging") | str_detect(SIFT, "deleterious") | str_detect(Condel, "deleterious"))
inner_join(VEP_Deleterious_3, ALL_3_SUPER_Frqx_Clin, by = c("X.Uploaded_variation" = "SNP"))

filter(VEP_FINAL_2, str_detect(SIFT, "deleterious")) %>% filter(str_detect(Condel, "deleterious")) %>% filter(str_detect(PolyPhen, "damaging"))
filter(VEP_FINAL_3, str_detect(SIFT, "deleterious")) %>% filter(str_detect(Condel, "deleterious")) %>% filter(str_detect(PolyPhen, "damaging"))

delOnes <- filter(VEP_FINAL_1, str_detect(SIFT, "deleterious")) %>% filter(str_detect(Condel, "deleterious")) %>% filter(str_detect(PolyPhen, "damaging"))

deleteriousOnes <- createWorkbook()
addWorksheet(deleteriousOnes, "BadVariants")
writeData(deleteriousOnes, x = delOnes, sheet = "BadVariants", colNames=TRUE, rowNames=FALSE, keepNA = TRUE)
saveWorkbook(deleteriousOnes, file = "BadVariants.xlsx", overwrite = TRUE)

```

# The End